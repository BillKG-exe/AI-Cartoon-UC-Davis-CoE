# Falsk API
Since our models has been developed in python, we decided to go with flask as it
will allow an ease in data processing and application of the models. The API
handles different operations for the frontend app.

### The API routes are comprised of the following:

`/api/generate` -  Initiates the image generation process based on the provided
prompt. If isEdit is True, it terminates the existing process for the given
prompt_id before starting a new one.

#### Input:
```json
{
    "chat_id": "1234",
    "id": "5678",
    "isChatOpened": true,
    "prompt": "people standing next to a red bus",
    "isEdit": false
}
```

The prompt is fed into a stable diffusion model from openAI that we finetuned
called GLIDE. GLIDE generate the set of images needed based on the batch size
specified.

#### output
```python
{ 'success': 1, 'status': 'generating the images...' }
```

`/api/checkStatus` -  Checks the status of the image generation process for the
given prompt_id. If the process is complete, it applies style transfer to the
generated images and save them. we apply style transfer using Multi-Style CartoonGan to
transfer the style of the images from real to a set of cartoon or art like styles. The
chosen style for this project are comprised of two oil painting style and one
cartoon style, Avatar.

#### Input:
```json
{
    "id": "5678"
}
```
The prompt is fed into a stable diffusion model from openAI that we finetuned
called GLIDE. GLIDE generate the set of images needed based on the batch size
specified. Afterwards, we apply style transfer using Multi-Style CartoonGan to
transfer the style of the images from real to a set of cartoon style. The
chosen style for this project are comprised of two oil painting style and one
cartoon style, Avatar.

If the thread is still running, we send `status: 1` to show that the thread is
still running. Otherwise, style transfer is applied to the images and saved.
`status: 0` is return in case of completion.
#### output
```python
{'status': 0, 'images': generated_images}`
```


`/api/promptHistory` -  Retrieves the history of prompts and associated images stored on the server.
#### Input:
```json
{
    "id": "5678"
}
```
#### output
```json
{
    "prompts": [
        {"id": "5678", "prompt": "A beautiful sunset over the mountains"},
        {"id": "1234", "prompt": "A cityscape at night"}
    ]
}
```

`/api/loadChatID` -  Loads the chat history for a specific prompt_id, encoding the images to Base64 format.
#### Input:
```json
{
    "id": "5678"
}
```
#### output
```json
{
    "prompts": [
        {"id": "5678", "prompt": "A beautiful sunset over the mountains", "images": ["5678_0.jpg", "5678_0_fake_1.jpg", "5678_0_fake_2.jpg", "5678_0_fake_3.jpg"]},
    ]
}
```

`/api/deleteChat` -   Deletes the chat history and associated images for a specific chatID.format.
#### Input:
```json
{
    "id": "5678"
}
```
#### output
```python
{'success': True || False}
```

## Folder structure
`history` - Holds the chat history of the user. This allows the user to load
old chats in case they need to retrieve certain images. This is used as a way
to track generated images and their prompts. The filename is the id of the
chat which is the same as the first prompt in the chat. The id could be
provided by the api caller. In our case, the id is the timestemp at which the
prompt as been sent.

`generated` - This folder is used to store all type of generated images. The
real image generated by the GLIDE model as well as images with style transfer
applied to it reside in that folder. When GLIDE generates the image, the image
is store in the generated folder, and afterwards, our style transfer module
retrieves the images and applies style transfer to it.

## GLIDE model
```python
# Path to the finetuned model 
glide_model_path = os.path.join(os.getcwd(), 'glide-finetuned-170.pt')

# Number of images to be generated
batch_size = 1      

# The  model used to generate the image from the prompt
text2im_model = BaseModel(model_path=glide_model_path, batch=batch_size)

# Create thread start job
task_result_queue = multiprocessing.Queue()

# Pass in the thread and its argument for processing
process = multiprocessing.Process(target=text2im_model.generate, args=(prompt, task_result_queue, str(prompt_id)))

# Start the thread
process.start()
```

The `text2im_mode.py` is comprised of a base model and an upsampler model. The
base model is used to generate images given a prompt. The upsampler model is
used to upsample the image to a bigger size. 

When generating an image, the base model uses the upsampler to apply upsampling
to the generated samples.

<!-- ## Table of Contents
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Contributing](#contributing)
- [License](#license) -->
